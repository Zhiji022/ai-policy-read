{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.0 requires langchain-core<0.4,>=0.3.0, but you have langchain-core 0.2.27 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU langchain-core==0.2.27 langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU pymupdf ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai-playground/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM-MIDTERM - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "documents = PyMuPDFLoader(file_path=\"data/Blueprint-for-an-AI-Bill-of-Rights.pdf\").load()\n",
    "\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.                   \n",
      "Generating:   0%|          | 0/10 [00:00<?, ?it/s][ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Technology use in social welfare', 'Healthcare system', 'Health disparities', 'Racial biases in medicine', 'Community input']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Human alternatives', 'Opt out', 'Automated systems', 'Fallback process', 'Human consideration']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Automated systems', 'Surveillance oversight', 'Algorithmic discrimination', 'Consent practices']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Automated systems', 'Surveillance oversight', 'Algorithmic discrimination', 'Consent practices']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Human alternatives', 'Opt out', 'Automated systems', 'Fallback process', 'Human consideration']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Existing law and policy', 'Automated system development', 'Ethical use of AI', 'Trustworthy Artificial Intelligence']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 2, 'score': 1.25}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Reporting expectations', 'National Artificial Intelligence Initiative Office', 'Traffic calming measures', 'Responsible AI ventures', 'AI ethics startups']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Existing law and policy', 'Automated system development', 'Ethical use of AI', 'Trustworthy Artificial Intelligence']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 1, 'structure': 1, 'relevance': 2, 'score': 1.25}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 0 times\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What expectations should be met by automated systems in terms of data privacy?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What guidelines should be followed for consent practices in automated systems according to the given context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How does the Blueprint for an AI Bill of Rights aim to inform private and public involvement with automated system development?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of a fallback process in automated systems according to the given context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How do new technologies impact health disparities according to the panelists in the healthcare system discussion?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How should individuals be able to opt out from automated systems and access human alternatives, according to the given context?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What benefits have been publicly described by the US Department of Transportation regarding \"traffic calming\" measures?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI-enabled nudification technology', 'Image-based abuse', 'Non-consensual intimate images', 'AI-powered cameras', 'Road safety habits']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How do principles for the ethical use of AI, such as those outlined in the Blueprint for an AI Bill of Rights, aim to inform private and public involvement with automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['OSTP conducted meetings', 'Private sector and civil society stakeholders', 'AI Bill of Rights', 'Positive use cases', 'Oversight possibilities']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What are the potential harms and impacts of AI-enabled nudification technology on individuals, particularly women?\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What stakeholders were involved in providing ideas related to the development of the Blueprint for an AI Bill of Rights?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the aims of the Blueprint for an AI Bill of Rights in relation to informing both private and public involvement in automated system development. It is specific and clear in its intent, focusing on a particular document (the Blueprint) and its implications for stakeholders in automated systems. The question does not rely on external references or context, making it independent and understandable. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for guidelines regarding consent practices in automated systems, referencing 'the given context' without providing any details about what that context entails. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to that context. To improve clarity and answerability, the question should either include a brief summary of the relevant context or be rephrased to ask for general guidelines on consent practices in automated systems without depending on external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What guidelines should be followed for consent practices in automated systems according to the given context?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the expectations for automated systems regarding data privacy. It is clear and specific, indicating a focus on the standards or requirements that should be upheld in this area. However, it could benefit from further clarification on what type of automated systems are being referred to (e.g., AI systems, data processing systems) and whether the expectations pertain to legal, ethical, or technical standards. Adding such details would enhance the clarity and answerability of the question.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the purpose of a fallback process in automated systems, referencing 'the given context' without providing any specific details about that context. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to the context mentioned. To improve clarity and answerability, the question should either include a brief description of the relevant context or be rephrased to focus on the general purpose of fallback processes in automated systems without depending on external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the purpose of a fallback process in automated systems according to the given context?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks how individuals can opt out from automated systems and access human alternatives, referencing 'the given context' without providing that context within the question itself. This reliance on unspecified context makes the question unclear and potentially unanswerable for those who do not have access to it. To improve clarity and answerability, the question could either include a brief description of the relevant context or be rephrased to ask about general practices or policies regarding opting out of automated systems and accessing human alternatives, independent of any specific context.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How should individuals be able to opt out from automated systems and access human alternatives, according to the given context?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the benefits of 'traffic calming' measures as described by the US Department of Transportation. It is specific in its focus on the benefits and the source of information (US Department of Transportation), making the intent clear. However, the term 'traffic calming' could be further clarified for those unfamiliar with it, as it encompasses various strategies. To improve clarity and answerability, the question could specify which types of traffic calming measures are being referred to (e.g., speed bumps, road narrowing, etc.) or provide a brief context about the Department's stance or recent publications on the topic.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the principles for the ethical use of AI as outlined in the Blueprint for an AI Bill of Rights and how these principles aim to inform both private and public involvement with automated systems. It is specific in its focus on ethical principles and their application, making the intent clear. However, the question assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context or details about it, which could hinder understanding for those not acquainted with the document. To improve clarity and answerability, the question could briefly summarize the key principles of the Blueprint or specify what aspects of private and public involvement it is referring to (e.g., regulation, implementation, ethical considerations).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How do principles for the ethical use of AI, such as those outlined in the Blueprint for an AI Bill of Rights, aim to inform private and public involvement with automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the potential harms and impacts of AI-enabled nudification technology on individuals, with a specific focus on women. It is clear in its intent to explore the negative consequences of this technology, making it understandable and answerable based on the details provided. However, the term 'nudification technology' may not be widely recognized, which could lead to some ambiguity. To improve clarity, the question could briefly define what is meant by 'nudification technology' or provide context on its applications. Overall, the question is specific and independent, allowing for a relevant response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: What are the potential harms and impacts of AI-enabled nudification technology on individuals, particularly women?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the impact of new technologies on health disparities as discussed by panelists in a healthcare system discussion. It is clear in its intent to understand the relationship between technology and health disparities, and it specifies the source of information (panelists in a discussion). However, the phrase 'according to the panelists' implies a reliance on specific discussions or statements made by individuals, which may not be accessible to everyone. To improve clarity and answerability, the question could specify the context of the discussion (e.g., a particular event, report, or study) or provide a brief overview of the panelists' perspectives to make the question more self-contained.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"How do new technologies impact health disparities according to the panelists in the healthcare system discussion?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the stakeholders involved in providing ideas for the development of the Blueprint for an AI Bill of Rights. It is specific and has a clear intent, as it seeks to identify the parties or groups that contributed to this initiative. However, it may benefit from additional context regarding what the Blueprint for an AI Bill of Rights entails or the timeframe of its development, as this could help clarify the scope of the stakeholders being referred to. Nonetheless, the question is largely independent and understandable as it stands.', 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for guidelines regarding consent practices in automated systems, referencing 'the given context' without providing any specific details about what that context entails. This reliance on unspecified external information makes the question unclear and potentially unanswerable for those who do not have access to the context mentioned. To improve clarity and answerability, the question could either include a brief summary of the relevant context or be rephrased to ask for general guidelines on consent practices in automated systems without depending on external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the purpose of a fallback process in automated systems, referencing 'the given context' without providing any specific details about that context. This reliance on unspecified external information makes the question unclear and unanswerable for those who do not have access to the context. To improve clarity and answerability, the question should either include a brief description of the relevant context or be rephrased to focus on the general purpose of fallback processes in automated systems without needing specific external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the process for individuals to opt out from automated systems and access human alternatives, referencing 'the given context' without providing that context within the question itself. This reliance on unspecified context makes the question unclear and potentially unanswerable for those who do not have access to it. To improve clarity and answerability, the question could either include a brief description of the relevant context or be rephrased to ask about general practices or guidelines for opting out of automated systems without needing specific external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"The benefits of 'traffic calming' measures have been publicly described by the US Department of Transportation, focusing on slowing vehicle speeds to improve safety and reduce accidents.\", 'verdict': 1}\n",
      "Generating:  10%|█         | 1/10 [00:04<00:37,  4.21s/it][ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 2, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['OSTP conducted meetings', 'Private sector and civil society stakeholders', 'AI Bill of Rights', 'Positive use cases', 'Oversight possibilities']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the principles for the ethical use of AI as outlined in the Blueprint for an AI Bill of Rights and how these principles aim to inform both private and public involvement with automated systems. It is specific in its focus on ethical principles and their application, making the intent clear. However, the question assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context or details about it, which may hinder understanding for those not acquainted with the document. To improve clarity and answerability, the question could briefly summarize the key principles of the Blueprint or specify what aspects of private and public involvement it is referring to (e.g., regulation, implementation, ethical considerations).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The expectations for automated systems in terms of data privacy include protecting the public from unchecked surveillance, ensuring heightened oversight of surveillance, limiting and proportionate surveillance, scoping limits on surveillance to protect rights and democratic values, and providing the public with mechanisms for appropriate and meaningful consent, access, and control over their data.', 'verdict': 1}\n",
      "Generating:  20%|██        | 2/10 [00:04<00:16,  2.12s/it][ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The Blueprint for an AI Bill of Rights aims to assist governments and the private sector in moving principles into practice, providing a broad, forward-leaning vision of recommended principles for automated system development and use. It does not detail existing laws but shares a vision to inform private and public involvement with automated systems where they have the potential to impact rights, opportunities, or access.', 'verdict': 1}\n",
      "Generating:  30%|███       | 3/10 [00:05<00:08,  1.22s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the impact of new technologies on health disparities as discussed by panelists in a healthcare system discussion. While it specifies the topic (new technologies and health disparities) and the context (panelists' discussion), it assumes familiarity with the specific discussion and the panelists involved, which may not be accessible to all audiences. To improve clarity and answerability, the question could provide a brief description of the panel discussion or specify which technologies and health disparities are being referred to. This would help ensure that the question is self-contained and understandable without requiring external context.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Blueprint for an AI Bill of Rights', 'Automated systems', 'Civil rights', 'Privacy', 'Responsible use of automated systems']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 2.75}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Automated systems', 'Algorithmic discrimination', 'Equity assessment', 'Representative data', 'Guarding against proxies']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What stakeholders were involved in the meetings conducted by OSTP regarding the development of the Blueprint for an AI Bill of Rights?\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Human alternatives', 'Automated system', 'Human reconsideration', 'Human fallback system', 'Sensitive domains']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 2, 'structure': 1, 'relevance': 2, 'score': 1.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Chicago police watch list', 'Artificial Intelligence Decisionmaking', 'Biometric Information Privacy Act', 'Model Cards framework', 'Black-Box Credit Models']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What extra protections are required for sensitive domains when it comes to the use of automated systems?\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How does the Blueprint for an AI Bill of Rights aim to protect privacy in the age of artificial intelligence?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the importance of conducting equity assessments in the design phase of automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question addresses the impact of AI-enabled \"nudification\" technology on women, specifically in the context of apps that allow non-technical users to create or alter images without consent. It is clear in its intent to explore the consequences of this technology on women\\'s personal and professional lives. However, the question is somewhat complex and may benefit from simplification or breaking down into more specific sub-questions to enhance clarity. For example, it could specify particular consequences or provide examples of how this technology has been used. Additionally, the term \"nudification\" may not be universally understood, so defining it could improve accessibility for a broader audience.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the Model Cards framework and how is it used in model reporting?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the stakeholders involved in meetings conducted by the OSTP (Office of Science and Technology Policy) concerning the development of the Blueprint for an AI Bill of Rights. It is specific in its focus on stakeholders and the context of the meetings, making the intent clear. However, it assumes familiarity with the OSTP and the specific meetings without providing any additional context or details about the Blueprint for an AI Bill of Rights. To improve clarity and answerability, the question could briefly define what the Blueprint for an AI Bill of Rights entails or specify the timeframe of the meetings in question.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: How does the proliferation of AI-enabled \"nudification\" technology, particularly in apps enabling non-technical users to create or alter images without consent, disproportionately impact women and potentially lead to devastating consequences in their personal and professional lives?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking about the aims of the Blueprint for an AI Bill of Rights in relation to privacy protection amidst the advancements in artificial intelligence. It does not rely on external references or context, making it independent and understandable. The intent is evident, seeking information on the specific measures or principles outlined in the Blueprint that address privacy concerns. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"How does the Blueprint for an AI Bill of Rights aim to protect privacy in the age of artificial intelligence?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the significance of conducting equity assessments during the design phase of automated systems. It is clear in its intent, specifying the focus on 'equity assessments' and their relevance to 'automated systems'. The question is independent and can be understood without needing additional context or references. However, it could be improved by specifying what aspects of equity assessments are being referred to (e.g., social, economic, or technological equity) or by providing examples of automated systems to contextualize the inquiry further. This would enhance clarity and allow for a more targeted response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the importance of conducting equity assessments in the design phase of automated systems?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for an explanation of the Model Cards framework and its application in model reporting. It is clear in its intent, specifying both the framework and its use case, making it understandable and answerable without needing additional context. The question is specific and independent, allowing for a direct response based on general knowledge of the Model Cards framework. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: What is the Model Cards framework and how is it used in model reporting?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the additional protections needed for sensitive domains regarding the use of automated systems. It is clear in its intent and specifies the focus on 'sensitive domains' and 'automated systems', making it understandable. However, the term 'sensitive domains' could be interpreted in various ways (e.g., healthcare, finance, personal data), which may lead to ambiguity in the answer. To improve clarity and answerability, the question could specify which sensitive domains are being referred to or provide examples of such domains. This would help narrow down the context and allow for a more precise response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: What extra protections are required for sensitive domains when it comes to the use of automated systems?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions explore the effects of AI-enabled nudification technology on individuals, specifically focusing on women. However, the first question emphasizes potential harms and impacts, while the second question is more general in its inquiry about effects, leading to differences in depth and breadth.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"How does the Blueprint for an AI Bill of Rights safeguard privacy in the era of AI by ensuring equal protection of rights, opportunities, and access to critical resources?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What proactive steps should be taken to ensure equity in the design phase of automated systems, and how should the results be reported for public accountability?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What framework informs the public about the operational transparency of machine learning systems, and what laws require lenders to provide explanations for credit decisions?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: What additional safeguards are necessary for sensitive domains concerning the utilization of automated systems to prevent unfair or harmful outcomes?\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"Stakeholders involved in providing ideas related to the development of the Blueprint for an AI Bill of Rights included Adobe, American Civil Liberties Union (ACLU), The Aspen Commission on Information Disorder, The Awood Center, The Australian Human Rights Commission, Biometrics Institute, The Brookings Institute, BSA | The Software Alliance, Cantellus Group, Center for American Progress, Center for Democracy and Technology, Center on Privacy and Technology at Georgetown Law, Christiana Care, Color of Change, Coworker, Data Robot, Data Trust Alliance, Data and Society Research Institute, Deepmind, EdSAFE AI Alliance, Electronic Privacy Information Center (EPIC), Encode Justice, Equal AI, Google, Hitachi's AI Policy Committee, The Innocence Project, Institute of Electrical and Electronics Engineers (IEEE), Intuit, Lawyers Committee for Civil Rights Under Law, Legal Aid Society, The Leadership Conference on Civil and Human Rights, Meta, Microsoft, The MIT AI Policy Forum, Movement Alliance Project, The National Association of Criminal Defense Lawyers, O'Neil Risk Consulting & Algorithmic Auditing, The Partnership on AI, Pinterest, The Plaintext Group, pymetrics, SAP, The Security Industry Association, Software and Information Industry Association (SIIA), Special Competitive Studies Project, Thorn, United for Respect, University of California at Berkeley Citris Policy Lab, University of California at Berkeley Labor Center, Unfinished/Project Liberty, Upturn, US Chamber of Commerce, US Chamber of Commerce Technology Engagement Center, A.I. Working Group, Vibrent Health, Warehouse Worker Resource Center, Waymap\", 'verdict': 1}\n",
      "Generating:  40%|████      | 4/10 [00:08<00:13,  2.21s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking about proactive steps for ensuring equity in the design phase of automated systems and how to report results for public accountability. It does not rely on external references and can be understood independently. However, it could be improved by specifying the type of automated systems being referred to (e.g., AI systems, software applications) to provide more context. This would help in tailoring the response to the specific domain of interest.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'AI-enabled \"nudification\" technology creates images where people appear to be nude, leading to non-consensual image-based abuse that disproportionately impacts women. As these tools become more sophisticated, the altered images are increasingly realistic and difficult to detect as inauthentic. Victims of non-consensual intimate images can experience devastating harm affecting their personal and professional lives, as well as their mental and physical health.', 'verdict': 1}\n",
      "Generating:  50%|█████     | 5/10 [00:09<00:08,  1.64s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the Blueprint for an AI Bill of Rights and its role in safeguarding privacy in the context of AI, specifically regarding equal protection of rights, opportunities, and access to resources. It is clear in its intent and specifies the topic of interest, making it understandable. However, the question could be improved by providing a brief context or definition of the 'Blueprint for an AI Bill of Rights' for those who may not be familiar with it. Additionally, clarifying what is meant by 'critical resources' could enhance the question's clarity. Overall, it is mostly clear and answerable, but slight adjustments could broaden its accessibility.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about additional safeguards needed for sensitive domains when using automated systems to prevent unfair or harmful outcomes. It is clear in its intent, specifying the focus on safeguards and the context of sensitive domains. However, the term 'sensitive domains' could be interpreted in various ways (e.g., healthcare, finance, criminal justice), which may lead to ambiguity in the answer. To improve clarity and answerability, the question could specify which sensitive domains are being referred to or provide examples. This would help narrow down the context and allow for a more focused response.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: What additional safeguards are necessary for sensitive domains concerning the utilization of automated systems to prevent unfair or harmful outcomes?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question combines two distinct inquiries: one about a framework for operational transparency in machine learning systems and another about laws requiring lenders to provide explanations for credit decisions. While each part of the question is clear in intent, the combination creates ambiguity regarding whether the answer should address both topics or focus on one. To improve clarity and answerability, the question could be split into two separate questions, such as: 'What framework informs the public about the operational transparency of machine learning systems?' and 'What laws require lenders to provide explanations for credit decisions?'. This would allow for more focused and direct responses to each inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What framework informs the public about the operational transparency of machine learning systems, and what laws require lenders to provide explanations for credit decisions?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How can equity be ensured in automated system design and reported for public accountability?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How does the AI Bill of Rights protect privacy in the AI era?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"Stakeholders involved in the meetings conducted by OSTP regarding the development of the Blueprint for an AI Bill of Rights included Adobe, American Civil Liberties Union (ACLU), The Aspen Commission on Information Disorder, The Awood Center, The Australian Human Rights Commission, Biometrics Institute, The Brookings Institute, BSA | The Software Alliance, Cantellus Group, Center for American Progress, Center for Democracy and Technology, Center on Privacy and Technology at Georgetown Law, Christiana Care, Color of Change, Coworker, Data Robot, Data Trust Alliance, Data and Society Research Institute, Deepmind, EdSAFE AI Alliance, Electronic Privacy Information Center (EPIC), Encode Justice, Equal AI, Google, Hitachi's AI Policy Committee, The Innocence Project, Institute of Electrical and Electronics Engineers (IEEE), Intuit, Lawyers Committee for Civil Rights Under Law, Legal Aid Society, The Leadership Conference on Civil and Human Rights, Meta, Microsoft, The MIT AI Policy Forum, Movement Alliance Project, The National Association of Criminal Defense Lawyers, O’Neil Risk Consulting & Algorithmic Auditing, The Partnership on AI, Pinterest, The Plaintext Group, pymetrics, SAP, The Security Industry Association, Software and Information Industry Association (SIIA), Special Competitive Studies Project, Thorn, United for Respect, University of California at Berkeley Citris Policy Lab, University of California at Berkeley Labor Center, Unfinished/Project Liberty, Upturn, US Chamber of Commerce, US Chamber of Commerce Technology Engagement Center, A.I. Working Group, Vibrent Health, Warehouse Worker Resource Center, Waymap\", 'verdict': 1}\n",
      "Generating:  60%|██████    | 6/10 [00:10<00:05,  1.46s/it][ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the importance of equity assessments specifically during the design phase, while the second question addresses how to ensure equity in the design process and its reporting for accountability. This indicates a difference in focus and depth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the protective measures of the AI Bill of Rights regarding privacy, focusing on similar themes and contexts. They share the same depth and breadth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about additional safeguards needed for sensitive domains when using automated systems to prevent unfair or harmful outcomes. It is clear in its intent, specifying the focus on safeguards and the context of sensitive domains. However, the term 'sensitive domains' could be interpreted in various ways (e.g., healthcare, finance, criminal justice), which may lead to ambiguity in the answer. To improve clarity and answerability, the question could specify which sensitive domains are being referred to or provide examples. This would help narrow down the context and allow for a more focused response.\", 'verdict': 1}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question combines two distinct inquiries: one about a framework for operational transparency in machine learning systems and another about laws requiring lenders to provide explanations for credit decisions. While each part of the question is clear in its intent, the combination creates ambiguity regarding whether the answer should address both topics or focus on one. To improve clarity and answerability, the question could be split into two separate questions, such as: 'What framework informs the public about the operational transparency of machine learning systems?' and 'What laws require lenders to provide explanations for credit decisions?'. This would allow for more focused and direct responses to each inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Automated systems', 'Technical companion', 'Principles', 'Protecting rights']\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What safeguards are needed for sensitive domains when using automated systems to avoid unfair or harmful results?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of the principles outlined in the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Automated systems', 'Consent withdrawal', 'Independent evaluation', 'Reporting']\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the necessary protections or safeguards for sensitive domains in the context of automated systems, focusing on the same issues of fairness and harm. They share similar constraints and requirements, as well as depth and breadth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What should entities allow in terms of consent withdrawal in automated systems according to the given context?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Equity in automated system design can be ensured through proactive equity assessments in the design phase, which involve reviewing potential input data, historical context, accessibility for people with disabilities, and societal goals to identify discrimination and effects on equity. This assessment should be inclusive of underserved communities and considered a core part of safety and efficacy reviews. Representative and robust data should be used, and proxies based on demographic information should be avoided to prevent algorithmic discrimination. Independent evaluations and clear reporting of algorithmic impact assessments are essential for public accountability.', 'verdict': 1}\n",
      "Generating:  70%|███████   | 7/10 [00:12<00:05,  1.77s/it][ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI Bill of Rights', 'Sensitive data', 'Sensitive domains', 'Surveillance technology', 'Underserved communities']\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the purpose of the principles outlined in the Blueprint for an AI Bill of Rights. It is specific and clear in its intent, focusing on the principles and their purpose. However, it assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context or details about what those principles are. To improve clarity and answerability, the question could briefly summarize the principles or specify which aspects of the purpose are of interest (e.g., ethical implications, societal impact).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What is the purpose of the principles outlined in the Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What is the purpose of applying The Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about consent withdrawal in automated systems, referencing 'the given context' without providing any specific details about that context. This reliance on unspecified external information makes the question unclear and difficult to answer for someone who does not have access to that context. To improve clarity and answerability, the question should either include a brief description of the relevant context or be rephrased to focus on general principles of consent withdrawal in automated systems without needing specific external references.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What should entities allow in terms of consent withdrawal in automated systems according to the given context?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the purpose of the principles outlined in the Blueprint for an AI Bill of Rights. It is specific and clear in its intent, as it directly seeks information about the purpose of these principles. However, the question assumes familiarity with the 'Blueprint for an AI Bill of Rights' without providing any context or details about what it entails. To improve clarity and answerability, the question could briefly describe what the Blueprint is or specify which principles are being referred to, ensuring that even those unfamiliar with the document can understand and respond appropriately.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the purpose of applying 'The Blueprint for an AI Bill of Rights', which is a specific and clear inquiry. It does not rely on external references or context, making it independent and self-contained. The intent is clear, as it seeks to understand the rationale behind the application of this blueprint. Therefore, it meets the criteria for clarity and answerability.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What is the purpose of applying The Blueprint for an AI Bill of Rights?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What benefits does implementing The Blueprint for an AI Bill of Rights provide in terms of protecting sensitive data related to specific domains?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about consent withdrawal in automated systems, referencing 'the given context' without providing that context within the question itself. This reliance on unspecified external information makes the question unclear and potentially unanswerable for those who do not have access to the context. To improve clarity and answerability, the question could either include a brief summary of the relevant context or be rephrased to focus on general principles of consent withdrawal in automated systems without needing specific external references. Additionally, specifying the type of entities or systems in question could enhance the clarity of the inquiry.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Automated systems', 'Sensitive domains', 'Human oversight', 'Meaningful access', 'Reporting']\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['AI-enabled systems', 'Technological diffusion', 'Urban planning', 'Smart city projects', 'Criminal justice system']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What expectations should be met by automated systems used within sensitive domains?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the benefits of implementing 'The Blueprint for an AI Bill of Rights' specifically in relation to protecting sensitive data across various domains. It is clear in its intent to understand the advantages of this implementation, and it specifies the focus on sensitive data protection. However, the phrase 'specific domains' is somewhat vague, as it does not clarify which domains are being referred to (e.g., healthcare, finance, education). To improve clarity and answerability, the question could specify the domains of interest or provide examples of the types of sensitive data being considered. This would help in providing a more targeted and relevant response.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: \"What benefits does implementing The Blueprint for an AI Bill of Rights provide in terms of protecting sensitive data related to specific domains?\"\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"How do panelists in the discussion address the potential harms of technology within the criminal justice system and what interventions do they suggest to protect against these harms?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the expectations for automated systems in sensitive domains, which is a clear and specific inquiry. It does not rely on external references and can be understood independently. However, it could benefit from further specificity regarding what is meant by 'sensitive domains' (e.g., healthcare, finance, law enforcement) and what types of expectations are being referred to (e.g., ethical considerations, performance standards, regulatory compliance). Adding these details would enhance clarity and allow for a more focused response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What expectations should be met by automated systems used within sensitive domains?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the benefits of implementing 'The Blueprint for an AI Bill of Rights' specifically in relation to protecting sensitive data across various domains. It is clear in its intent to understand the advantages of this implementation, and it specifies the focus on sensitive data protection. However, the question could be improved by clarifying what is meant by 'specific domains'—for example, are these domains related to healthcare, finance, education, etc.? Providing examples or specifying the domains of interest would enhance clarity and make the question more answerable. Overall, while the question is relatively clear, it could benefit from additional detail regarding the domains in question.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What criteria should automated systems in sensitive domains meet, including considerations for human alternatives and fallback mechanisms?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking how panelists address potential harms of technology in the criminal justice system and what interventions they suggest. It does not rely on external references and can be understood independently. However, it could be improved by specifying which panel discussion is being referred to, as there may be multiple discussions on this topic. Adding context about the panelists or the specific technologies in question could enhance clarity and provide a more focused framework for the answer.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"How do panelists in the discussion address the potential harms of technology within the criminal justice system and what interventions do they suggest to protect against these harms?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What advantages does The Blueprint for an AI Bill of Rights offer in safeguarding domain-specific sensitive data?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"How do panelists propose addressing the potential risks of technology within the criminal justice system and what measures do they recommend to safeguard against these risks?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on the general purpose of The Blueprint for an AI Bill of Rights, while the second question specifically addresses its advantages in relation to safeguarding sensitive data. This indicates a difference in depth and breadth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the criteria that automated systems in sensitive domains should meet, including considerations for human alternatives and fallback mechanisms. It is specific and has a clear intent, focusing on the criteria for automated systems in a particular context. However, the term 'sensitive domains' could be interpreted in various ways (e.g., healthcare, finance, security), which may lead to ambiguity in the answer. To improve clarity and answerability, the question could specify what is meant by 'sensitive domains' or provide examples of such domains. This would help ensure that the response is relevant and targeted.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What criteria should automated systems in sensitive domains meet, including human alternatives and fallbacks?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking about the proposals made by panelists regarding the risks of technology in the criminal justice system and the recommended measures to mitigate these risks. It does not rely on external references or context, making it independent and self-contained. The intent is straightforward, seeking information on both the proposals and the recommended measures. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How can panelists address technology risks in criminal justice and recommend safeguards?\"\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The answer to given question is not present in context', 'verdict': -1}\n",
      "Generating:  80%|████████  | 8/10 [00:20<00:07,  3.60s/it][ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the standards or requirements for automated systems in sensitive domains, but the second question introduces additional elements such as human alternatives and fallbacks, which expands its breadth and depth of inquiry.', 'verdict': 0}\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"Both questions inquire about the role of panelists in discussing technology's impact on the criminal justice system, focusing on potential harms and suggested interventions or safeguards. They share similar constraints and depth of inquiry.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Algorithmic Discrimination Protections', 'Automated systems', 'Facial recognition technology', 'Discriminatory decisions', 'Guardrails protecting the public']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the importance of guardrails protecting the public in the context of algorithmic discrimination?\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Automated systems used within sensitive domains should meet expectations laid out in the framework, including narrowly scoped data and inferences, tailored to the situation, human consideration before high-risk decisions, meaningful access to examine the system, demonstrate access to human alternatives, consideration, and fallback. Reporting should include an assessment of timeliness and additional burden for human alternatives, aggregate statistics about who chooses the human alternative, and results of the assessment about brevity, clarity, and accessibility of notice and opt-out instructions. Reporting on accessibility, timeliness, and effectiveness of human consideration and fallback should be made public at regular intervals. For systems used in sensitive domains, reporting should include information about training and governance procedures for these technologies, documentation of goals and assessment of meeting those goals, consideration of data included, and documentation of governance of reasonable access to the technology. Reporting should be provided in a clear and machine-readable manner.', 'verdict': 1}\n",
      "Generating:  90%|█████████ | 9/10 [00:23<00:03,  3.47s/it][ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the importance of guardrails in protecting the public from algorithmic discrimination. It is clear in its intent, specifying the topic of interest (guardrails and algorithmic discrimination) and seeking information on their significance. However, the term 'guardrails' could be interpreted in various ways, such as legal regulations, ethical guidelines, or technical safeguards. To improve clarity and answerability, the question could specify what type of guardrails are being referred to or provide a brief context about the specific aspects of algorithmic discrimination being considered (e.g., in hiring practices, law enforcement, etc.).\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: What is the importance of guardrails protecting the public in the context of algorithmic discrimination?\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What role do guardrails play in safeguarding the public from discriminatory practices in automated systems, considering the impact on various aspects of individuals' lives?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the role of guardrails in protecting the public from discriminatory practices in automated systems, specifically considering their impact on various aspects of individuals' lives. It is clear in its intent and specifies the topic of interest (guardrails and automated systems), making it understandable. However, the question could be improved by clarifying what is meant by 'guardrails' (e.g., regulations, ethical guidelines, technical measures) and specifying which aspects of individuals' lives are being referred to (e.g., employment, healthcare, education). This would enhance clarity and allow for a more focused response.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"How do guardrails protect against discrimination in automated systems, impacting individuals' lives?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions address the role of guardrails in preventing algorithmic discrimination, focusing on their importance and impact on individuals. They share similar constraints and depth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 3, 'depth': 3, 'structure': 3, 'relevance': 3, 'score': 3.0}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Data privacy', 'Automated systems', 'Consent withdrawal', 'Independent evaluation', 'Reporting']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: \"What expectations should be met by automated systems in terms of data privacy and user control?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the expectations for automated systems regarding data privacy and user control. It is clear in its intent, specifying the focus on expectations related to data privacy and user control. However, it could benefit from being more specific about the context or type of automated systems being referred to (e.g., AI systems, online services, etc.), as well as what aspects of data privacy and user control are of interest (e.g., data collection practices, user consent mechanisms). Adding these details would enhance clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: \"What expectations should be met by automated systems in terms of data privacy and user control?\"\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: \"What privacy protections and user control mechanisms should automated systems incorporate by default?\"\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the privacy protections and user control mechanisms that should be incorporated by default in automated systems. It is specific and clear in its intent, seeking information on best practices or standards for privacy in automated systems. The question is independent as it does not rely on external references or context to be understood. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: \"What privacy measures should automated systems include?\"\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question focuses on expectations regarding data privacy and user control, while the second question specifically addresses privacy measures. This indicates a difference in depth and breadth of inquiry, as the first question is broader and more comprehensive.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'Automated systems should include privacy measures such as data access and correction, consent withdrawal and data deletion, support for individuals to make consent, access, and control decisions, independent evaluation of data policies, reporting mechanisms for users to know what data is being used, privacy by design and default, data minimization, use-case scope limits, risk identification and mitigation, and privacy-preserving security measures.', 'verdict': 1}\n",
      "Generating: 100%|██████████| 10/10 [00:35<00:00,  3.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What benefits have been publicly described by ...</td>\n",
       "      <td>[ \\nENDNOTES\\n12. Expectations about reporting...</td>\n",
       "      <td>The benefits of 'traffic calming' measures hav...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the Blueprint for an AI Bill of Right...</td>\n",
       "      <td>[SECTION TITLE\\n \\n \\n \\n \\n \\n \\nApplying The...</td>\n",
       "      <td>The Blueprint for an AI Bill of Rights aims to...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What expectations should be met by automated s...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\nDATA PRIVACY \\nWHAT SHOULD ...</td>\n",
       "      <td>The expectations for automated systems in term...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What stakeholders were involved in providing i...</td>\n",
       "      <td>[APPENDIX\\n• OSTP conducted meetings with a va...</td>\n",
       "      <td>Stakeholders involved in providing ideas relat...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What stakeholders were involved in the meeting...</td>\n",
       "      <td>[APPENDIX\\n• OSTP conducted meetings with a va...</td>\n",
       "      <td>Stakeholders involved in the meetings conducte...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What advantages does The Blueprint for an AI B...</td>\n",
       "      <td>[ \\n \\n \\nApplying The Blueprint for an AI Bil...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How can equity be ensured in automated system ...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\n \\nWHAT SHOULD BE EXPECTED ...</td>\n",
       "      <td>Equity in automated system design can be ensur...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What criteria should automated systems in sens...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\n \\nHUMAN ALTERNATIVES, \\nCO...</td>\n",
       "      <td>Automated systems used within sensitive domain...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What privacy measures should automated systems...</td>\n",
       "      <td>[ \\n \\n \\n \\n \\n \\nDATA PRIVACY \\nWHAT SHOULD ...</td>\n",
       "      <td>Automated systems should include privacy measu...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does AI \"nudification\" tech affect women's...</td>\n",
       "      <td>[ \\n \\n  \\n \\nSAFE AND EFFECTIVE \\nSYSTEMS \\nW...</td>\n",
       "      <td>AI-enabled \"nudification\" technology creates i...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'data/Blueprint-for-an-AI-Bill-of-...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What benefits have been publicly described by ...   \n",
       "1  How does the Blueprint for an AI Bill of Right...   \n",
       "2  What expectations should be met by automated s...   \n",
       "3  What stakeholders were involved in providing i...   \n",
       "4  What stakeholders were involved in the meeting...   \n",
       "5  What advantages does The Blueprint for an AI B...   \n",
       "6  How can equity be ensured in automated system ...   \n",
       "7  What criteria should automated systems in sens...   \n",
       "8  What privacy measures should automated systems...   \n",
       "9  How does AI \"nudification\" tech affect women's...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ \\nENDNOTES\\n12. Expectations about reporting...   \n",
       "1  [SECTION TITLE\\n \\n \\n \\n \\n \\n \\nApplying The...   \n",
       "2  [ \\n \\n \\n \\n \\n \\nDATA PRIVACY \\nWHAT SHOULD ...   \n",
       "3  [APPENDIX\\n• OSTP conducted meetings with a va...   \n",
       "4  [APPENDIX\\n• OSTP conducted meetings with a va...   \n",
       "5  [ \\n \\n \\nApplying The Blueprint for an AI Bil...   \n",
       "6  [ \\n \\n \\n \\n \\n \\n \\nWHAT SHOULD BE EXPECTED ...   \n",
       "7  [ \\n \\n \\n \\n \\n \\n \\nHUMAN ALTERNATIVES, \\nCO...   \n",
       "8  [ \\n \\n \\n \\n \\n \\nDATA PRIVACY \\nWHAT SHOULD ...   \n",
       "9  [ \\n \\n  \\n \\nSAFE AND EFFECTIVE \\nSYSTEMS \\nW...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  The benefits of 'traffic calming' measures hav...         simple   \n",
       "1  The Blueprint for an AI Bill of Rights aims to...         simple   \n",
       "2  The expectations for automated systems in term...         simple   \n",
       "3  Stakeholders involved in providing ideas relat...         simple   \n",
       "4  Stakeholders involved in the meetings conducte...         simple   \n",
       "5  The answer to given question is not present in...  multi_context   \n",
       "6  Equity in automated system design can be ensur...  multi_context   \n",
       "7  Automated systems used within sensitive domain...  multi_context   \n",
       "8  Automated systems should include privacy measu...  multi_context   \n",
       "9  AI-enabled \"nudification\" technology creates i...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "1  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "2  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "3  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "4  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "5  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "6  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "7  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "8  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  \n",
       "9  [{'source': 'data/Blueprint-for-an-AI-Bill-of-...          True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate_with_langchain_docs(documents, 10, distributions, with_debugging_logs=True)\n",
    "testset_df = testset.to_pandas()\n",
    "testset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_df.to_csv('data/testset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
