{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain langchain-community langchain-openai langchain-core langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet pdfplumber pymupdf4llm pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/wd9_8vm53d9f8r6psp18wxyh0000gn/T/ipykernel_72911/879689266.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "import tiktoken\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "# huggingface model\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain_community.document_loaders.base import BaseLoader\n",
    "from langchain_text_splitters.base import TextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pymupdf to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf4llm, pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1 =  pymupdf.open(\"data/Blueprint-for-an-AI-Bill-of-Rights.pdf\")\n",
    "len(docs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  'Blank Page',\n",
       "  56,\n",
       "  {'kind': 1, 'xref': 1711, 'page': 55, 'to': Point(0.0, 0.0), 'zoom': 0.0}],\n",
       " [1,\n",
       "  'Untitled',\n",
       "  56,\n",
       "  {'kind': 1,\n",
       "   'xref': 1714,\n",
       "   'page': 55,\n",
       "   'to': Point(-37.0, -173.0),\n",
       "   'zoom': 0.0}],\n",
       " [1,\n",
       "  'Untitled',\n",
       "  55,\n",
       "  {'kind': 1,\n",
       "   'xref': 1712,\n",
       "   'page': 54,\n",
       "   'to': Point(-37.0, 318.0),\n",
       "   'zoom': 0.0}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1.get_toc(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[page 0 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf,\n",
       " page 1 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf,\n",
       " page 2 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs1[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad filename: type(filename)=<class 'list'> filename=[page 0 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf, page 1 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cw/wd9_8vm53d9f8r6psp18wxyh0000gn/T/ipykernel_72911/605968986.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmd_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymupdf4llm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ai-playground/lib/python3.11/site-packages/pymupdf4llm/helpers/pymupdf_rag.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(doc, pages, hdr_info, write_images, embed_images, image_path, image_format, image_size_limit, force_text, page_chunks, margins, dpi, page_width, page_height, table_strategy, graphics_limit, fontsize_limit, ignore_code, extract_words, show_progress)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mGRAPHICS_LIMIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphics_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mFONTSIZE_LIMIT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfontsize_limit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpymupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymupdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;31m# for reflowable documents allow making 1 page for the whole document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_reflowable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ai-playground/lib/python3.11/site-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2900\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count_fz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mJM_mupdf_show_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJM_mupdf_show_errors_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad filename: type(filename)=<class 'list'> filename=[page 0 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf, page 1 of data/Blueprint-for-an-AI-Bill-of-Rights.pdf]."
     ]
    }
   ],
   "source": [
    "\n",
    "md_text = pymupdf4llm.to_markdown(docs1[:2])\n",
    "type(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents 1\n",
    "docs1 =  PyMuPDFLoader(\"data/Blueprint-for-an-AI-Bill-of-Rights.pdf\").load()\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o-mini\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = tiktoken_len,\n",
    ")\n",
    "\n",
    "split_chunks_1 = text_splitter.split_documents(docs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents 2\n",
    "docs2 = PDFPlumberLoader('data/NIST.AI.600-1.pdf').load()\n",
    "\n",
    "split_chunks_2 = text_splitter.split_documents(docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split_chunks_1), len(split_chunks_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [*split_chunks_1, *split_chunks_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Snowflake/snowflake-arctic-embed-m\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "collection_name = \"ai-policy\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=768, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model,\n",
    ")\n",
    "\n",
    "vector_store.add_documents(documents)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt and llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = \"\"\"\\\n",
    "You are an expert in AI ethics and policy. The CEO of a company is asking legal advice from you regarding their investment in AI application. Given a provided context and a question, you must answer the question. If you do not know the answer, you must state that you do not know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(RAG_PROMPT)\n",
    "\n",
    "rag_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rag_chain(rag_prompt_template, vector_store, llm):\n",
    "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "    rag_chain = ({\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "                    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "                    | {\"response\": rag_prompt_template | llm | StrOutputParser(), \"context\": itemgetter(\"context\")})\n",
    "    return rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, InstanceOf\n",
    "class RAGRunnables(BaseModel):\n",
    "    rag_prompt_template: InstanceOf[ChatPromptTemplate]\n",
    "    vector_store: InstanceOf[QdrantVectorStore]\n",
    "    llm: InstanceOf[ChatOpenAI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_runnables = RAGRunnables(\n",
    "                        rag_prompt_template = ChatPromptTemplate.from_template(RAG_PROMPT),\n",
    "                        vector_store = vector_store,\n",
    "                        llm = rag_llm\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_rag_chain(rag_runnables.rag_prompt_template, rag_runnables.vector_store, rag_runnables.llm)\n",
    "chain.invoke({'question': 'Who are the authors of NIST Trustworthy and Responsible AI?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chain.invoke({'question': 'Who are the authors of NIST Trustworthy and Responsible AI?'})\n",
    "results['context'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
